---
outline: [2, 3]
tags: 
  - AWS
publishDate: 2022/03/05
---

# S3

> 被称为无限存储

是 AWS 很重要的部件。很多应用和 AWS 服务都依赖于 S3。

## 用例

- 备份和存储
- 灾难恢复
- 归档
- 混合云存储
- 托管 app，媒体文件
- 数据湖和大数据分析
- 软件交付更新
- 托管静态网站

## 桶(Buckets)

- S3 允许用户将对象(文件)存储到 buckets 中，桶可以看做是顶级目录
- Buckets 必须有一个人全球唯一的名称(所有账户所有区域)
- Buckets 是定义在区域级别的，即使我们要在全球有一个唯一的名字，但它依旧是在特定区域创建的
- 命名约定
  - 不能大写
  - 没有下划线
  - 3 - 63 字符
  - 不能是 IP
  - 数字或小写字母开头
  - 不能以 xn--开头
  - 不能以-s3alias 后缀结尾

## 对象(Objects)

- 每一个对象都有 key
- key 是全路径：
  - s3://my-bucket/**my_file.txt**
  - s3://my-bucket/**my_folder/secondary_folder/my_file.txt**
- key 是由前缀 + 对象名称结合组成的
- 是上传的文件的正文内容
  - 最大 5TB
  - 如果大于 5GB，必须使用 分段上传，一旦文件超过 100 MB，建议进行分段上传
- 对象有元数据 metadata：键值对列表，系统或用户元数据
- 有标签：例如他们的 Unicode 密钥，值最多为 10，对安全和生命周期很有用
- 版本 ID：如果启用了版本

## 安全：

- 基于用户：
  - IAM 策略
- 基于资源：
  - Bucket 策略，可以从 S3 控制台分配，允许特定的用户进入 S3 ✅ 比较常用
  - Object Access control list：ACL，更精细的安全性，可以禁用
  - Bucket Access control list：ACL，Bucket 级别，不太常用，可以禁用
- 注意：什么情况下 IAM 可以访问 S3？
  - 当 用户的 IAM 权限 **允许** 或者 资源策略 **允许**
  - **并且**actions 中没有明确的 **DENY**(拒绝)
- 加密：使用加密密钥对对象进行加密。

### Bucket 策略

> https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/userguide/access-policy-language-overview.html

- 基于 JSON 的
  - Resource - 定义策略于哪些存储桶和对象
  - Effect - 允许/拒绝
  - Action - 一组 API，本例是所有 s3 的 API
  - Principal - 适用于的人
- 使用 S3 Bucket 策略可以：
  - 授予对存储桶的公共访问权限
  - 强制对象在上传时加密
  - 授予对另一个账户的访问权限
- 先于默认加密之前评估

```json
{
	"Version": "2012-10-17",
	"Id": "S3PolicyIdl”,
	"Statement": [
	"Sid": "statement1"
	“Effect": “Deny'
	“Principal": "*",
	"Action": ["s3:*"],
	"Resource"：“arn:awS:s3:::examplebucket/",
	"Condition": {
		"NotIpAddress": {
			"ans:SourceIp": "192.168.143.188/32"
		}
	}
}

```

> 创建 Buckets 时，AWS 会默认设置很多 Block，叫做阻止公有访问，是用于防止数据泄露，如果这些设置一直打开，即使设置了策略也不能被访问：

![[S3 Block]](/src/assets/aws-s3-block.png)

### 加密

- 加密有四种方式：
  - SSE 服务端加密
    - SSE-S3 使用默认管理的密钥加密
    - SSE-KMS 使用 KMS 密钥来管理加密密钥
    - SSE-C 使用可狐提供的密钥
  - CSE 客户端加密

### SSE-S3

- 由 AWS 处理、管理和拥有，我们永远无法访问此密钥
- 加密的安全类型必须是 AES-256
- 必须将头部设置为：`x-amz-server-side-encryption: AES256`
- 默认对新 buckets 和对象开启

### SSE-KMS

- 密钥由 KMS 管理
- 自己拥有对密钥的控制权，而且可以使用 CloudTrail 编辑密钥用法
- 必须将头部设置为：`x-amz-server-side-encryption: aws:kms`

> 使用 KMS 局限性

- KMS 有自己的 API
- 每个 KMS 的 API 调用将计入 KMS 配额(根据地区)，每秒 5000~30000 个请求
- 可以通过配额控制台可以增加配额

### SSE-C

- 密钥在 AWS 之外管理
- AWS S3 不会存储你提供的密钥
- 必须使用 HTTPS
- 必须将密钥作为每个请求的 HTTP 头的一部分进行传递
- AWS 控制台不可见，仅当使用 AWS 的 CLI 或 SDK 才支持

### CSE 客户端加密

- 使用一些库来加密
- 客户端必须在将数据发送到 AWS 前自行加密
- 从 AWS S3 检索数据后在客户端进行解密
- 所以客户端完全管理密钥和加密周期

### 传输中加密

- 也称为 SSL/TLS
- S3 暴露两个端点：
  - HTTP 端点 - 未加密
  - HTTPS 端点 - 传输中加密

### HTTPS

- 在使用 S3 时，推荐使用 HTTPS
- 在使用 SSE-C 时，必须使用 HTTPS

### CORS

可以在 property 设置是否允许跨域

### MFA Delete

- 强制用户在 S3 执行某些操作在硬件设备上生成代码
- 必须的场景：
  - 永久删除对象版本
  - 暂停版本控制
- 不必须的场景：
  - 开启版本控制
  - 列出已删除的版本
- 想要使用 MFA Delete，必须先启用版本控制
- 只有 Bucket 的拥有者才能启用/禁用 MFA Delete

### 访问日志

- 便于审计
- 任何到 S3 的请求，来自于任何账户，授权与否都会作为文件记录在另一个 S3 中
- 可以使用数据分析工具来分析
- 目标日志 bucket 必须在同一个 AWS 域
- 有特定的格式
- 注意：不要将记录 Bucket 设置为被监控的 Bucket，这会创建一个日志循环，Bucket 会成倍增长

### 预签名 URL

- 使用 S3 控制台、AWS CLI 或 SDK
- URL 有过期时间：
  - S3 控制台：至多 12 小时
  - CLI：至多 168 小时
- 用户拿到 URL 的会继承生成者的 GET / PUT 权限
- 用例：
  - 不想公开一个文件的情况下共享文件给其他人
  - 只允许登录用户下载高级视频
  - 允许不断变化的用户列表通过动态生成 URL 下载文件
  - 临时允许用户上传文件到精确位置

### 锁

### Glacier Vault Lock

> 冰川保险库锁

- 适应 WORM(Write Once Read Many)模型
- 创建一个 Vault Lock 策略
- 然后锁定。那么任何人都无法再修改/删除它
- 这对于合规性和数据保留非常有用

### 对象锁

- 必须启用版本控制
- 适应 WORM(Write Once Read Many)模型
- 在指定时间内阻止对象版本删除
- 两种保留模式：
  - 合规模式：对象版本不能被任何用户覆盖或删除，包括根用户。这意味着一旦你进入合规模式，没有人能改变任何事。
  - 治理模式：在这种情况下，大多数用户无法覆盖或删除对象版本或更改其锁定设置。但是管理员用户，具有特殊权限，通过 IAM 授予的他们可以更改保留或删除直接一个对象。
- 得设置保留时长(可以延长)
- 合法持有：
  - 无限期的，永远被保护，无论任何保留期
  - 拥有 IAM 权限(S3 PutObjectLegalHold)的人 可以选择获取任何对象并对其进行法律控制或将其删除。

### 访问点

- 访问点可以简化 S3 的安全管理
- 每个访问点有：
  - DNS 名称(来源 VPC 或 互联网)
  - 访问点策略

### VPC 来源

- 在 VPC 访问中无需通过互联网
- 必须创建 VPC 端点
- VPC 端点也有策略，且必须允许到目标桶和访问点的访问

### S3 对象 Lambda

- 使用 aws lambda 函数在 caller application 检索之前修改对象
- 只需要一个 Bucket，然后创建 S3 访问点和 S3Lambda 函数
- 用例：
  - PII 数据(personally identifiable information)
  - 将数据从 XML 转换成 JSON
  - 动态调整图像的大小和水印

## 版本控制

- 可以对文件进行版本控制
- 可以在 Bucket 级别开启
- 同样的 key 就会覆盖 version
- 对 Bucket 进行版本控制是最佳实践：
  - 保护防止意外删除，可以恢复到某一个版本
  - 可以轻易回滚到之前的版本
- 注意：
  - 任何没有被控制版本的文件其`version`默认是`null`
  - 如果暂停了版本控制，不会删除以前的版本，所以这是一个安全的操作

## 复制(CRR&SRR)

> CRR 跨区域复制
> SRR 同区域辅助

- 必须启用版本控制在源和目标桶中
- CRR 两个桶的区域必须不同
- SRR 两个桶的区域必须相同
- 桶可以在不同的 aws 账户中
- 复制是异步的
- 必须为 S3 授予适当的 IAM 权限
- 用例
  - CRR - 遵从规定、低延迟、跨账户复制
  - SRR - 聚合日志、生产和测试账户之间执行实时复制
- 启用复制后，只有新对象会被复制
- 如果想复制已存在的对象可以使用 S3 批量复制
  - 复制已存在的和复制失败的
- 对于删除操作
  - 可以复制删除标记，默认不开启，可以选择开启
  - 有版本 ID 的删除不会被复制，就是永久删除
- 没有链式影响：
  - 如果 A 桶复制到了 B 桶，B 复制到了 C
  - **那么 A 中创建新的对象不会复制到 C**

## 存储类型

### Standard - General Purpose

- 99.99% 可用性
- 用于经常访问的数据
- 低延迟和高吞吐量
- 可以承受两个并发的设施故障
- 用例：大数据分析，移动和游戏应用，

### Infrequent Access

- 不需要频繁访问，但是需要的时候可以快速访问
- 比标准成本更低
- 标准 - 低频访问(S3 Standard-IA)
  - 99.9%可用性
  - 用例：灾难恢复，备份
- 单区 - 低频访问(S3 One zone-IA)
  - 单个 AZ 耐用性 99.999999999%，AZ 破坏则数据丢失
  - 99.5%可用性
  - 用例：存储备份的二级副本，或者可以重新创建的数据

### Glacier

- 低成本，用于存档和备份
- 价格：为存储和对象检索付费
- 冰川即刻检索：
  - 毫秒级检索，例如每季度访问一次的数据
  - 最短存储时间为 90 天
- 冰川灵活检索：
  - Expedited：1-5 分钟，Standard：3 - 5 小时，Bulk 是免费的：5-12 小时
  - 最低存储 90 天
  - 长期保存且每年访问一次的数据
- 冰川深度存档 - 对于长期存储
  - Standard 12 小时，Bulk48 小时
  - 最低存储 180 天
  - 长期保存且每年访问少于一次的数据

### Intelligent - Tiering

- 每个月支付少量费用于监控和自动分级
- 自动在访问层之间移动对象
- 无检索费用
- 适用于访问模式发生变化或未知的数据
- 自动频繁访问层：默认
- 非频繁访问层：30 天未访问的对象
- 存档即时访问层：90 天未访问的对象
- 存档访问层(可选)：可配置 90 ~ 700 多天
- 深度存档访问层(可选)：可配置 180 天~700 多天

### 存储类型对比

- 可以将对象转换为不同存储类型
- 对于不经常访问的对象，移动到 Standard IA
- 对于要归档的对象，不需要快速访问的，移入 Glacier 或者 Glacier Deep Archive
- 也可以使用生命周期规则来自动移动
  ![存储类型对比](/src/assets/aws-s3-store-type1.png)
  ![存储类型对比](/src/assets/aws-s3-store-type2.png)

### 存储类型分析

- 帮助我们决定什么时候转换对象为正确的存储类型
- 推荐 适用于标准和标准 IA：
  - 不适用于单区 IA 或者冰川
- 分析程序生成的 csv 报告每天都会更新
- 24-48 小时可以看到由此产生的数据分析

## 生命周期

### Actions

- 过度 - 配置对象转换到另一个存储类型
  - 比如创建 60 天后移动到 Standard IA
  - 比如 6 个月后移动到 Glacier
- 过期 - 配置对象多久后过期
  - 比如访问日志对象 365 天后删除
  - 可以被用来删除老版本文件(如果开启了版本控制)
  - 可以被用来删除未完成的多段上传
- 可以对指定前缀的对象创建规则
- 可以对指定对象标签创建规则

### 场景试炼

**#** app 在资料传到 S3 后从原图创建图片，缩略图，缩略图可以很容易重新创建，只需要保存 60 天。原图应该在 60 天内可以被立即检索，而且至多用户等待 6 小时，该如何设计？

**>** 原图应该使用 Standard 存储，同时设置转换的生命周期 60 天后移动到 Glacier。
**>** 缩略图可以在单区 IA，因为很少访问且很容易被重新创建，同时设置生命周期过期时间为 60 天。

**#** 可以立即恢复 30 天内的已删除对象，即时发生的频率很低，之后最多 365 天，删除的对象可以在 48 小时内恢复。

**>** 启用版本控制，为删除的对象添加删除标记，所以可以被快速恢复。
**>** 设置生命周期，将非当前版本对象转换到标准 IA
**>** 设置生命周期，将非当前版本转换到 Glacier Deep Archive

## 请求者支付

- 通常 Buckets 拥有者支付存储和数据传输费用
- 请求者支付：依然是拥有者来支付存储费用，但是下载产生的数据传输和网络成本由请求者支付
- 对于与其他账户共享大型数据集很有用
- 请求者必须经过 AWS 身份验证，不能是匿名的，AWS 才知道该向谁收费

## 事件通知

- 对象创建，对象移除，对象恢复，对象复制等都是事件
- 可以通过过滤来筛选对象
- 用例：自动对某些事件做出反应，比如对上传的图片生成缩略图，首先创建事件通知，然后将它发送到几个目的地，可能是一个 SNS，也可能是 SQS 或者 Lambda。
- 可以根据需要创建任意数量的 S3 事件
- 可以将他们发送到任何目标
- 事件通知一般在数秒内交付，但是有时候可能需要一分钟或更长时间

### EventBridge

- 所有的事件都会进入 EventBridge。
- 可以在 EventBridge 中设置规则，可以将事件发送到超过 18 种不同的 AWS 服务作为目的地。
- 高级过滤功能：比如元数据，对象大小和名称等。
- 可以一次性发送到多个目的地
- 更多功能：存档事件，重播事件，更可靠的交付

### 性能

- 默认情况下 S3 自动缩放到高请求率，延迟 100-200 毫秒
- 每个前缀每秒应用可以获得至少 3500 个 PUT COUPY POST DELETE 或者 5500 个 GET HEAD 请求
- Bucket 中的前缀没有数量限制
- 前缀：bucket 以后到文件以前

### 如何优化

- 分段上传：
  - 推荐对于大于 100MB 的文件，如果是 5GB 以上必须分段
  - 并行上传
- S3 传输加速
  - 通过将文件传输到 AWS 边缘站点来提高传输速度，最小化公共互联网的数量
  - 与分段上传兼容

### S3 字节范围获取

- 通过并行的 GET 请求特定的字节范围
- 失败的情况下获取特定字节范围
- 可以加快下载速度
- 或用于检索一些文件信息

## S3 Select & Glacier Select

- 通过执行服务端过滤来使用 SQL 检索更少的数据
- 通过行、列过滤(简单的 SQL 语句)
- 更少的网络传输和客户端 CPU 成本

## 批量操作

- 通过一个简单的请求在 S3 对象上执行批量操作
  - 修改对象的元数据和属性
  - 在 S3buckets 之间复制对象
  - 加密
  - 修改 ACLSs 标签
  - 从 S3 Glacier 恢复对象
  - 调用 Lambda 函数为每个对象执行自定义动作
- 作业由对象列表、要执行的动作、和可选参数组成
- 为什么使用 S3 批量操作而不是自己写脚本？
  - 重试管理，跟踪进度，发送完成通知，生成报告等
- 调用 S3 inventory 获取对象列表，并使用 S3 Select 过滤对象
- 用例：找到所有未加密对象并使用 S3 批处理操作全部加密
